# -*- coding: utf-8 -*-
"""StockPrice_RNN_LSTM_Amardeep.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/17gPJPS3Yl0iPO2_jb-yFHS_XLeq-BnpI
"""

!pip install keras-tuner

import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)
import matplotlib.pyplot as plt
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Dropout,LSTM
import numpy as np
from sklearn.preprocessing import MinMaxScaler
import math
from sklearn.metrics import mean_squared_error
from kerastuner.engine.hyperparameters import HyperParameters
from tensorflow import keras
from tensorflow.keras import layers
from kerastuner.tuners import RandomSearch

df_test = pd.read_csv('./Google_Stock_Price_Test.csv')
df_train = pd.read_csv('./Google_Stock_Price_Train.csv')
df = pd.concat([df_test,df_train])

df.head()

df.info()

df.describe()

df.columns

df.shape

df.isnull().sum()

df.dtypes

df    = df.loc[:,["Open"]].values
train = df[:len(df)-50]
test = df[len(train):]
# reshape
train = train.reshape(train.shape[0],1)

train.shape

plt.plot(train);
plt.title("Closing prices for the data");

from sklearn.preprocessing import MinMaxScaler
scaler = MinMaxScaler(feature_range= (0,1)) # defining of Scaler
train_scaled = scaler.fit_transform(train) # applying to Scaler to train

plt.plot(train_scaled)
plt.show()

# We add first 50 location to "X_train" and we 51. location to "y_train" .
X_train = []
y_train = []
timesteps = 50

for i in range(timesteps, train_scaled.shape[0]):
    X_train.append(train_scaled[i-timesteps:i,0])
    y_train.append(train_scaled[i,0])

X_train, y_train = np.array(X_train), np.array(y_train)


# Reshaping
X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], 1)  # Dimension of array is 3.

# --- RNN ---

# Importing the Keras libraries and packages

from keras.models import Sequential
from keras.layers import Dense
from keras.layers import SimpleRNN
from keras.layers import Dropout # it block to overfitting

# Initialising the RNN
regressor = Sequential()

# Adding the first RNN layer and some Dropout regularisation
regressor.add(SimpleRNN(units = 50,activation='tanh', return_sequences = True, input_shape = (X_train.shape[1], 1)))
regressor.add(Dropout(0.2))

# Adding a second RNN layer and some Dropout regularisation.
regressor.add(SimpleRNN(units = 50,activation='tanh', return_sequences = True))
regressor.add(Dropout(0.2))

# Adding a third RNN layer and some Dropout regularisation.
regressor.add(SimpleRNN(units = 50,activation='tanh', return_sequences = True))
regressor.add(Dropout(0.2))

# Adding a fourth RNN layer and some Dropout regularisation.
regressor.add(SimpleRNN(units = 50))
regressor.add(Dropout(0.2))


# Adding the output layer
regressor.add(Dense(units = 1))

# Compiling the RNN
regressor.compile(optimizer = 'adam', loss = 'mean_squared_error')

# Fitting the RNN to the Training set
regressor.fit(X_train, y_train, epochs = 100, batch_size = 32)

inputs = df[len(df) - len(test) - timesteps:]
inputs = scaler.transform(inputs)  # min max scaler

X_test = []
for i in range(timesteps, inputs.shape[0]):
    X_test.append(inputs[i-timesteps:i, 0]) # 0 dan 50 ye, 1 den 51 e gibi kaydirarark 50 eleman aliyoruz
X_test = np.array(X_test)
X_test = X_test.reshape(X_test.shape[0], X_test.shape[1], 1)

predicted_data = regressor.predict(X_test)
predicted_data = scaler.inverse_transform(predicted_data)

plt.figure(figsize=(8,4), dpi=80, facecolor='w', edgecolor='k')
plt.plot(test,color="orange",label="Real value")
plt.plot(predicted_data,color="c",label="RNN predicted result")
plt.legend()
plt.xlabel("Days")
plt.ylabel("Values")
plt.grid(True)
plt.show()

from keras.models import Sequential
from keras.layers import Dense
from keras.layers import LSTM
from sklearn.preprocessing import MinMaxScaler
from sklearn.metrics import mean_squared_error

model = Sequential()
model.add(LSTM(10, input_shape=(None,1)))
model.add(Dense(1))
model.compile(loss="mean_squared_error",optimizer='Adam')
model.fit(X_train,y_train,epochs=50, batch_size=1)

predicted_data2=model.predict(X_test)
predicted_data2=scaler.inverse_transform(predicted_data2)

plt.figure(figsize=(8,4), dpi=80, facecolor='w', edgecolor='k')
plt.plot(test,color="LimeGreen",label="Real values")
plt.plot(predicted_data2,color="Gold",label="Predicted LSTM result")
plt.legend()
plt.xlabel("Days")
plt.ylabel("Values")
plt.grid(True)
plt.show()

plt.figure(figsize=(8,4), dpi=80, facecolor='w', edgecolor='k')
plt.plot(test,color="green", linestyle='dashed',label="Real values")
plt.plot(predicted_data2,color="blue", label="LSTM predicted result")
plt.plot(predicted_data,color="red",label="RNN predicted result") # ben ekledim
plt.legend()
plt.xlabel("Days)")
plt.ylabel("Real values")
plt.grid(True)
plt.show()

# Calculate RMSE for Train and Test data
def calculate_rmse(actual, predicted):
    return np.sqrt(mean_squared_error(actual, predicted))

# For RNN
train_predicted_rnn = regressor.predict(X_train)
train_predicted_rnn = scaler.inverse_transform(train_predicted_rnn)
rmse_train_rnn = calculate_rmse(scaler.inverse_transform(y_train.reshape(-1, 1)), train_predicted_rnn)
rmse_test_rnn = calculate_rmse(test, predicted_data)

# For LSTM
train_predicted_lstm = model.predict(X_train)
train_predicted_lstm = scaler.inverse_transform(train_predicted_lstm)
rmse_train_lstm = calculate_rmse(scaler.inverse_transform(y_train.reshape(-1, 1)), train_predicted_lstm)
rmse_test_lstm = calculate_rmse(test, predicted_data2)

# Display the RMSE values
print(f"Train RMSE for RNN: {rmse_train_rnn}")
print(f"Test RMSE for RNN: {rmse_test_rnn}")
print(f"Train RMSE for LSTM: {rmse_train_lstm}")
print(f"Test RMSE for LSTM: {rmse_test_lstm}")

# Function to calculate MAPE
def calculate_mape(actual, predicted):
    actual, predicted = np.array(actual), np.array(predicted)
    return np.mean(np.abs((actual - predicted) / actual)) * 100

# For RNN
mape_train_rnn = calculate_mape(scaler.inverse_transform(y_train.reshape(-1, 1)), train_predicted_rnn)
mape_test_rnn = calculate_mape(test, predicted_data)

# For LSTM
mape_train_lstm = calculate_mape(scaler.inverse_transform(y_train.reshape(-1, 1)), train_predicted_lstm)
mape_test_lstm = calculate_mape(test, predicted_data2)

# Display the MAPE values
print(f"Train MAPE for RNN: {mape_train_rnn:.2f}%")
print(f"Test MAPE for RNN: {mape_test_rnn:.2f}%")
print(f"Train MAPE for LSTM: {mape_train_lstm:.2f}%")
print(f"Test MAPE for LSTM: {mape_test_lstm:.2f}%")

